{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard packages\n",
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# mario packages\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import *\n",
    "\n",
    "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "\n",
    "# Import Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "\n",
    "# Import algo\n",
    "from stable_baselines3 import A2C, PPO\n",
    "\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, SubprocVecEnv, DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_logdir = os.path.abspath(\".\")\n",
    "# reward_log_path = os.path.join(tensorboard_logdir, 'reward_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $tensorboard_logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_logdir = os.path.abspath(\"./mario/reg_model\")\n",
    "reward_log_path = os.path.join(tensorboard_logdir, 'reward_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 20216), started 19:05:05 ago. (Use '!kill 20216' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b68ae9ec771e65f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b68ae9ec771e65f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $tensorboard_logdir --port=6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      timesteps     reward  best_reward\n",
      "2328  2328000.0   1857.85        3080.0\n",
      "2120  2120000.0   2141.05        3079.0\n",
      "1749  1749000.0    2303.9        3077.0\n",
      "2370  2370000.0    1960.9        3077.0\n",
      "1418  1418000.0    2113.7        3077.0\n",
      "2489  2489000.0    2031.2        3077.0\n",
      "2255  2255000.0   1991.75        3076.0\n",
      "1375  1375000.0    1837.3        3076.0\n",
      "1934  1934000.0   2331.95        3075.0\n",
      "2147  2147000.0   2091.45        3075.0\n",
      "      timesteps     reward  best_reward\n",
      "2621  2621000.0    2220.5        3069.0\n",
      "2620  2620000.0   1775.05        3061.0\n",
      "2619  2619000.0   2388.55        3062.0\n",
      "2618  2618000.0    1835.3        3067.0\n",
      "2617  2617000.0   1901.75        3057.0\n"
     ]
    }
   ],
   "source": [
    "reward_ccmodel = pd.read_csv(\"mario/cc_model/reward_log.csv\")\n",
    "reward_ccmodel = reward_ccmodel.loc[reward_ccmodel.timesteps!=\"timesteps\", :].reset_index(drop=True)\n",
    "reward_ccmodel[\"timesteps\"] = reward_ccmodel[\"timesteps\"].astype(\"float\")\n",
    "reward_ccmodel[\"best_reward\"] = reward_ccmodel[\"best_reward\"].astype(\"float\")\n",
    "reward_ccmodel = reward_ccmodel.sort_values(by=\"best_reward\", ascending=False)\n",
    "print(reward_ccmodel.head(10))\n",
    "print(reward_ccmodel.sort_values(by=\"timesteps\", ascending=False).head(5))\n",
    "# reward_ccmodel.loc[reward_ccmodel.timesteps==\"timesteps\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      timesteps   reward  best_reward\n",
      "2272    2273000  2289.75       3068.0\n",
      "2447    2448000  2649.50       3068.0\n",
      "2345    2346000  2287.05       3068.0\n",
      "2346    2347000  2334.40       3068.0\n",
      "2351    2352000  2586.05       3068.0\n",
      "2443    2444000  2557.75       3068.0\n",
      "2352    2353000  2543.20       3068.0\n",
      "2425    2426000  2628.05       3068.0\n",
      "2519    2520000  2150.35       3068.0\n",
      "2424    2425000  2517.30       3068.0\n",
      "      timesteps   reward  best_reward\n",
      "2523    2524000  2163.10       3062.0\n",
      "2522    2523000  2032.20       3062.0\n",
      "2521    2522000  2332.50       3063.0\n",
      "2520    2521000  2584.80       3062.0\n",
      "2519    2520000  2150.35       3068.0\n"
     ]
    }
   ],
   "source": [
    "reward_regmodel = pd.read_csv(\"mario/reg_model/reward_log.csv\").sort_values(by=\"best_reward\", ascending=False)\n",
    "print(reward_regmodel.head(10))\n",
    "print(reward_regmodel.sort_values(by=\"timesteps\", ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     timesteps  reward  best_reward\n",
      "329     330000  779.45       2971.0\n",
      "70       71000  629.80       2661.0\n",
      "351     352000  827.55       2445.0\n",
      "346     347000  710.35       2293.0\n",
      "322     323000  585.45       2288.0\n",
      "312     313000  751.90       2264.0\n",
      "324     325000  619.85       1861.0\n",
      "119     120000  643.50       1827.0\n",
      "338     339000  824.90       1820.0\n",
      "344     345000  794.70       1814.0\n",
      "     timesteps  reward  best_reward\n",
      "388     389000  596.30       1314.0\n",
      "387     388000  492.15        938.0\n",
      "386     387000  577.30       1053.0\n",
      "385     386000  516.30        966.0\n",
      "384     385000  575.40       1263.0\n"
     ]
    }
   ],
   "source": [
    "reward_ccmodel_a2c = pd.read_csv(\"../actorcritic/mario/cc_model/reward_log.csv\").sort_values(by=\"best_reward\", ascending=False)\n",
    "print(reward_ccmodel_a2c.head(10))\n",
    "print(reward_ccmodel_a2c.sort_values(by=\"timesteps\", ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     timesteps  reward  best_reward\n",
      "218     219000  751.95       2245.0\n",
      "191     192000  684.15       2030.0\n",
      "229     230000  660.80       1864.0\n",
      "217     218000  639.50       1803.0\n",
      "207     208000  660.15       1615.0\n",
      "215     216000  650.70       1607.0\n",
      "278     279000  717.05       1599.0\n",
      "39       40000  558.15       1592.0\n",
      "216     217000  658.45       1565.0\n",
      "205     206000  615.25       1492.0\n",
      "    timesteps  reward  best_reward\n",
      "69     357000  588.75       1195.0\n",
      "68     356000  578.35       1035.0\n",
      "67     355000  430.50        915.0\n",
      "66     354000  482.20        733.0\n",
      "65     353000  584.70       1212.0\n"
     ]
    }
   ],
   "source": [
    "reward_regmodel_a2c_df1 = pd.read_csv(\"../actorcritic/mario/reg_model/reward.csv\").sort_values(by=\"best_reward\", ascending=False)\n",
    "reward_regmodel_a2c_df2 = pd.read_csv(\"../actorcritic/mario/reg_model/reward_log.csv\")\n",
    "reward_regmodel_a2c_df2.columns = reward_regmodel_a2c_df1.columns\n",
    "reward_regmodel_a2c_df2 = reward_regmodel_a2c_df2.sort_values(by=\"best_reward\", ascending=False)\n",
    "reward_regmodel_a2c = pd.concat([reward_regmodel_a2c_df1, reward_regmodel_a2c_df2], axis=0)\n",
    "print(reward_regmodel_a2c.head(10))\n",
    "print(reward_regmodel_a2c.sort_values(by=\"timesteps\", ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard packages\n",
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "# mario packages\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import *\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "\n",
    "# Import Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "\n",
    "# Import algo\n",
    "from stable_baselines3 import A2C, PPO\n",
    "\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, SubprocVecEnv, DummyVecEnv\n",
    "\n",
    "class CoinCollectorSuperMarioBrosEnv(SuperMarioBrosEnv):\n",
    "    #score btn 2 time frames can maybe go upto 8000 so we can just divide by 100 (reference https://www.mariowiki.com/Point)\n",
    "    reward_range = (-15, 100)\n",
    "\n",
    "    def __init__(self, rom_mode='vanilla', lost_levels=False, target=None):\n",
    "        super().__init__(rom_mode=rom_mode, lost_levels=lost_levels, target=target)\n",
    "\n",
    "        # variable to keep track of score deltas\n",
    "        self._score_last = 0\n",
    "\n",
    "    @property\n",
    "    def _score_reward(self):\n",
    "        _reward = self._score - self._score_last\n",
    "        self._score_last = self._score\n",
    "        return _reward/100\n",
    "\n",
    "    # This should override the parent function\n",
    "    def _get_reward(self):\n",
    "        return self._x_reward + self._score_reward + self._time_penalty + self._death_penalty\n",
    "\n",
    "'''\n",
    "The code below registers this new environment in gym for us to reference later. Code borrowed from _registration.py of gym_super_mario_bros\n",
    "'''\n",
    "def _register_coin_collector_mario_stage_env(id, **kwargs):\n",
    "    \"\"\"\n",
    "    Register a Super Mario Bros. (1/2) stage environment with OpenAI Gym.\n",
    "\n",
    "    Args:\n",
    "        id (str): id for the env to register\n",
    "        kwargs (dict): keyword arguments for the SuperMarioBrosEnv initializer\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # register the environment\n",
    "    gym.envs.registration.register(\n",
    "        id=id,\n",
    "        # entry_point='.:CoinCollectorSuperMarioBrosEnv',\n",
    "        entry_point=CoinCollectorSuperMarioBrosEnv,\n",
    "        max_episode_steps=9999999,\n",
    "        reward_threshold=9999999,\n",
    "        kwargs=kwargs,\n",
    "        nondeterministic=True,\n",
    "    )\n",
    "\n",
    "def _register_all_coin_collector_envs():\n",
    "    # a template for making individual stage environments\n",
    "    _ID_TEMPLATE = 'CoinCollectorSuperMarioBrosEnv-{}-{}-v{}'\n",
    "    # A list of ROM modes for each level environment\n",
    "    _ROM_MODES = [\n",
    "        'vanilla',\n",
    "        'downsample',\n",
    "        'pixel',\n",
    "        'rectangle'\n",
    "    ]\n",
    "\n",
    "    # iterate over all the rom modes, worlds (1-8), and stages (1-4)\n",
    "    for version, rom_mode in enumerate(_ROM_MODES):\n",
    "        for world in range(1, 9):\n",
    "            for stage in range(1, 5):\n",
    "                # create the target\n",
    "                target = (world, stage)\n",
    "                # setup the frame-skipping environment\n",
    "                env_id = _ID_TEMPLATE.format(world, stage, version)\n",
    "                print(f\"Registering Coin Collector {env_id} in gym for use later on.\")\n",
    "                _register_coin_collector_mario_stage_env(env_id, rom_mode=rom_mode, target=target)\n",
    "                print(f\"Successfully registered coin collector env {env_id}!\")\n",
    "\n",
    "def create_gym_env_from_level(world, stage, version, use_coin_collector_env):\n",
    "    level_suffix = f\"{world}-{stage}-v{version}\"\n",
    "    if not use_coin_collector_env:\n",
    "        level = f\"SuperMarioBros-{level_suffix}\"\n",
    "        env = gym_super_mario_bros.make(level)\n",
    "    else:\n",
    "        env_set = set(gym.envs.registration.registry.env_specs.copy().keys())\n",
    "        level = f\"CoinCollectorSuperMarioBrosEnv-{level_suffix}\"\n",
    "        if level not in env_set:\n",
    "            # register all these custom environments for the first time\n",
    "            _register_all_coin_collector_envs()\n",
    "\n",
    "        assert level in set(\n",
    "            gym.envs.registration.registry.env_specs.copy().keys()\n",
    "        ), f\"Looks like {level} was not registered correctly!\"\n",
    "        env = gym.make(level)\n",
    "\n",
    "    return env\n",
    "\n",
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, info\n",
    "\n",
    "class ResizeEnv(gym.ObservationWrapper):\n",
    "    def __init__(self, env, size):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        (oldh, oldw, oldc) = env.observation_space.shape\n",
    "        newshape = (size, size, oldc)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255,\n",
    "            shape=newshape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, frame):\n",
    "        height, width, _ = self.observation_space.shape\n",
    "        frame = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "        if frame.ndim == 2:\n",
    "            frame = frame[:,:,None]\n",
    "        return frame\n",
    "\n",
    "def create_mario_env(world, stage, version, use_coin_collector_env):\n",
    "    env = create_gym_env_from_level(world, stage, version, use_coin_collector_env)\n",
    "    env = JoypadSpace(env, COMPLEX_MOVEMENT)\n",
    "    env = SkipFrame(env, skip=4)\n",
    "    env = GrayScaleObservation(env, keep_dim=True)\n",
    "    env = ResizeEnv(env, size=84)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecFrameStack(env, 4, channels_order='last')\n",
    "    return env\n",
    "\n",
    "class MarioNet(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim):\n",
    "        super(MarioNet, self).__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with th.no_grad():\n",
    "            n_flatten = self.cnn(th.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (1, 84, 84, 4)\n"
     ]
    }
   ],
   "source": [
    "# <world> is a number in {1, 2, 3, 4, 5, 6, 7, 8} indicating the world\n",
    "world = 1\n",
    "# <stage> is a number in {1, 2, 3, 4} indicating the stage within a world\n",
    "stage = 1\n",
    "version = 3\n",
    "use_coin_collector_env = True\n",
    "\n",
    "env = create_mario_env(world, stage, version, use_coin_collector_env)\n",
    "\n",
    "env.reset()\n",
    "state, reward, done, info = env.step([0])\n",
    "print('state:', state.shape) #Color scale, height, width, num of stacks\n",
    "\n",
    "\n",
    "env = create_mario_env(world, stage, version, use_coin_collector_env)\n",
    "plays = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_epoch = 1418000 #change as per the values inferred from the graph\n",
    "# best_model_path = 'mario/cc_model/best_model_{}.zip'.format(best_epoch)\n",
    "\n",
    "# # Load the best model\n",
    "# model = PPO.load(best_model_path)\n",
    "# record_env = RecordVideo(env, f\"mario_plays/cc_model/{best_epoch}\", name_prefix=\"mario_ppo\")\n",
    "\n",
    "# for ep in range(plays):\n",
    "#     state = record_env.reset()\n",
    "#     done = False\n",
    "#     while not done:\n",
    "#         action, _ = model.predict(state)\n",
    "#         state, reward, done, info = record_env.step(action)\n",
    "#         record_env.render()\n",
    "# print(f\"Episode {ep} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0][\"flag_get\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (1, 84, 84, 4)\n"
     ]
    }
   ],
   "source": [
    "# <world> is a number in {1, 2, 3, 4, 5, 6, 7, 8} indicating the world\n",
    "world = 1\n",
    "# <stage> is a number in {1, 2, 3, 4} indicating the stage within a world\n",
    "stage = 1\n",
    "version = 3\n",
    "use_coin_collector_env = False\n",
    "\n",
    "env = create_mario_env(world, stage, version, use_coin_collector_env)\n",
    "\n",
    "env.reset()\n",
    "state, reward, done, info = env.step([0])\n",
    "print('state:', state.shape) #Color scale, height, width, num of stacks\n",
    "\n",
    "\n",
    "env = create_mario_env(world, stage, version, use_coin_collector_env)\n",
    "plays = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 0 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 1 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 2 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n",
      "Episode 3 done\n"
     ]
    }
   ],
   "source": [
    "best_epoch = 848000 #change as per the values inferred from the graph\n",
    "best_model_path = 'mario/reg_model/best_model_{}.zip'.format(best_epoch)\n",
    "\n",
    "# Load the best model\n",
    "model = PPO.load(best_model_path)\n",
    "record_env = RecordVideo(env, f\"mario_plays/reg_model/{best_epoch}\", name_prefix=\"mario_ppo\")\n",
    "\n",
    "for ep in range(plays):\n",
    "    state = record_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(state)\n",
    "        state, reward, done, info = record_env.step(action)\n",
    "        record_env.render()\n",
    "        print(f\"Episode {ep} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model record plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cc_model_timestep = 2328000\n",
    "best_reg_model_timestep = 2273000\n",
    "\n",
    "best_cc_model = 'mario/cc_model/best_model_{}.zip'.format(best_cc_model_timestep)\n",
    "best_cc_model = PPO.load(best_cc_model)\n",
    "\n",
    "best_reg_model = 'mario/reg_model/best_model_{}.zip'.format(best_reg_model_timestep)\n",
    "best_reg_model = PPO.load(best_reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_rate(model=None, plays=1000, world=1, stage=1, version=3, use_coin_collector_env=True):\n",
    "    get_count = 0\n",
    "    coin_count = 0\n",
    "    coin_collection = []\n",
    "\n",
    "    env = env_setup(world=world, stage=stage, version=version, use_coin_collector_env=use_coin_collector_env)\n",
    "\n",
    "    for _ in tqdm(range(plays)):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(state)\n",
    "            state, reward, done, info = env.step(action)\n",
    "        if info[0]['flag_get'] == True:\n",
    "            get_count += 1\n",
    "        coin_count_current_play = info[0]['coins']\n",
    "        coin_collection.append(coin_count_current_play)\n",
    "        coin_count += info[0]['coins']\n",
    "    # print(f'flag get count: {get_count}')\n",
    "    # print(f'total coin count: {coin_count}')\n",
    "\n",
    "    return get_count, coin_count, coin_collection\n",
    "\n",
    "def env_setup(world=1, stage=1, version=3, use_coin_collector_env=True):\n",
    "\n",
    "    env = create_mario_env(world=world, stage=stage, version=version, use_coin_collector_env=use_coin_collector_env)\n",
    "    env.reset()\n",
    "    state, reward, done, info = env.step([0])\n",
    "    print('state:', state.shape) #Color scale, height, width, num of stacks\n",
    "\n",
    "    env = create_mario_env(world=world, stage=stage, version=version, use_coin_collector_env=use_coin_collector_env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 996\n"
     ]
    }
   ],
   "source": [
    "# cc model trial 1\n",
    "pass_count_cc, coin_count_cc, coin_collected_t1_cc = pass_rate(best_cc_model, use_coin_collector_env=True)\n",
    "print(pass_count_cc, coin_count_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (1, 84, 84, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [44:44<00:00,  2.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cc model trial 2\n",
    "pass_count_cc, coin_count_cc, coin_collected_t2_cc = pass_rate(best_cc_model, use_coin_collector_env=True)\n",
    "print(pass_count_cc, coin_count_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (1, 84, 84, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [44:23<00:00,  2.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cc model trial 3\n",
    "pass_count_cc, coin_count_cc, coin_collected_t3_cc = pass_rate(best_cc_model, use_coin_collector_env=True)\n",
    "print(pass_count_cc, coin_count_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 700\n"
     ]
    }
   ],
   "source": [
    "# reg model trial 1\n",
    "pass_count_reg, coin_count_reg = pass_rate(best_reg_model, use_coin_collector_env=False)\n",
    "print(pass_count_reg, coin_count_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (1, 84, 84, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [48:48<00:00,  2.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reg model trial 2\n",
    "pass_count_reg, coin_count_reg, coin_collected_t2_reg = pass_rate(best_reg_model, use_coin_collector_env=False)\n",
    "print(pass_count_reg, coin_count_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (1, 84, 84, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [47:59<00:00,  2.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reg model trial 3\n",
    "pass_count_reg, coin_count_reg, coin_collected_t3_cc = pass_rate(best_reg_model, use_coin_collector_env=False)\n",
    "print(pass_count_reg, coin_count_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mario_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
